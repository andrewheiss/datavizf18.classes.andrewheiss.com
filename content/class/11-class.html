---
title: "Text"
date: "2018-11-13"
citeproc: false
bibliography: ../../static/bib/references.bib
csl: ../../static/bib/chicago-syllabus-no-bib.csl
output:
  blogdown::html_page:
    template: ../../pandoc/toc-title_html.template
    toc: true
    toc_depth: 4
editor_options: 
  chunk_output_type: console
---

<!-- BLOGDOWN-HEAD -->
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #ffffff;
    color: #a0a0a0;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
div.sourceCode
  { color: #1f1c1b; background-color: #ffffff; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span. { color: #1f1c1b; } /* Normal */
code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
code span.an { color: #ca60ca; } /* Annotation */
code span.at { color: #0057ae; } /* Attribute */
code span.bn { color: #b08000; } /* BaseN */
code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #924c9d; } /* Char */
code span.cn { color: #aa5500; } /* Constant */
code span.co { color: #898887; } /* Comment */
code span.cv { color: #0095ff; } /* CommentVar */
code span.do { color: #607880; } /* Documentation */
code span.dt { color: #0057ae; } /* DataType */
code span.dv { color: #b08000; } /* DecVal */
code span.er { color: #bf0303; text-decoration: underline; } /* Error */
code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
code span.fl { color: #b08000; } /* Float */
code span.fu { color: #644a9b; } /* Function */
code span.im { color: #ff5500; } /* Import */
code span.in { color: #b08000; } /* Information */
code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
code span.op { color: #1f1c1b; } /* Operator */
code span.ot { color: #006e28; } /* Other */
code span.pp { color: #006e28; } /* Preprocessor */
code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #ff5500; } /* SpecialString */
code span.st { color: #bf0303; } /* String */
code span.va { color: #0057ae; } /* Variable */
code span.vs { color: #bf0303; } /* VerbatimString */
code span.wa { color: #bf0303; } /* Warning */
</style>
<!-- /BLOGDOWN-HEAD -->

<h2>Contents</h2>
<div id="TOC">
<ul>
<li><a href="#slides">Slides</a></li>
<li><a href="#data-to-download">Data to download</a></li>
<li><a href="#live-code">Live code</a></li>
<li><a href="#tidy-text-analysis">Tidy text analysis</a><ul>
<li><a href="#part-of-speech-tagging">Part-of-speech tagging</a></li>
<li><a href="#tokens-and-word-counts">Tokens and word counts</a><ul>
<li><a href="#single-words">Single words</a></li>
<li><a href="#bigrams">Bigrams</a></li>
<li><a href="#bigrams-and-probability">Bigrams and probability</a></li>
</ul></li>
<li><a href="#sentiment-analysis">Sentiment analysis</a></li>
<li><a href="#tf-idf">tf-idf</a></li>
<li><a href="#topic-modeling">Topic modeling</a></li>
<li><a href="#fingerprinting">Fingerprinting</a><ul>
<li><a href="#hapax-legomena">Hapax legomena</a></li>
<li><a href="#verse-length">Verse length</a></li>
<li><a href="#text-features">Text features</a></li>
</ul></li>
</ul></li>
<li><a href="#clearest-and-muddiest-things">Clearest and muddiest things</a></li>
</ul>
</div>

<h2 id="slides">Slides</h2>
<p><a href="/slides/MPA-635_2018-11-13.pdf">Download the slides from today’s lecture</a>.</p>
<figure>
<a href="/slides/MPA-635_2018-11-13.pdf"><img src="/images/slides/slides_2018-11-13.png" alt="First slide" /></a>
</figure>
<h2 id="data-to-download">Data to download</h2>
<p>Download these and put them in a folder named “data” in an RStudio project:</p>
<ul>
<li><i class="fas fa-table"></i> <a href="/data/lds-scriptures.csv">LDS Scriptures</a></li>
<li><i class="fas fa-table"></i> <a href="/data/bom_annotated.csv">Book of Mormon (PoS tagged)</a></li>
</ul>
<h2 id="live-code">Live code</h2>
<p>Use this link to see the code that I’m actually typing:</p>
<ul>
<li><i class="fas fa-globe"></i> <a href="https://andhs.co/live-code" class="uri">https://andhs.co/live-code</a></li>
</ul>
<p>I’ve saved the R script to Dropbox, and that link goes to a live version of that file. Refresh or re-open the link as needed to copy/paste code I type up on the screen.</p>
<h2 id="tidy-text-analysis">Tidy text analysis</h2>
<p>In class, we looked at a bunch of different methods for analyzing text. At the foundation of all this text analysis, all we’re really doing is counting words in fancy ways. This stuff isn’t magic—it’s just counting.</p>
<p>We’ll start by loading the libraries we’ll need, as well as the data linked above.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw">library</span>(tidyverse)</a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="kw">library</span>(tidytext)</a>
<a class="sourceLine" id="cb1-3" data-line-number="3"><span class="kw">library</span>(gutenbergr)</a>
<a class="sourceLine" id="cb1-4" data-line-number="4"><span class="kw">library</span>(topicmodels)</a>
<a class="sourceLine" id="cb1-5" data-line-number="5"><span class="kw">library</span>(textfeatures)</a>
<a class="sourceLine" id="cb1-6" data-line-number="6"></a>
<a class="sourceLine" id="cb1-7" data-line-number="7"><span class="co"># For cool natural language processing; go to</span></a>
<a class="sourceLine" id="cb1-8" data-line-number="8"><span class="co"># https://statsmaths.github.io/cleanNLP/ for documentation and examples</span></a>
<a class="sourceLine" id="cb1-9" data-line-number="9"><span class="kw">library</span>(cleanNLP)</a></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="co"># Text from http://scriptures.nephi.org/</span></a>
<a class="sourceLine" id="cb2-2" data-line-number="2">scriptures &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data/lds-scriptures.csv&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2-3" data-line-number="3"><span class="st">  </span><span class="kw">select</span>(volume_title, book_title, chapter_number, verse_number, scripture_text)</a>
<a class="sourceLine" id="cb2-4" data-line-number="4"></a>
<a class="sourceLine" id="cb2-5" data-line-number="5"><span class="co"># Get just the Book of Mormon and make sure the book names are in order</span></a>
<a class="sourceLine" id="cb2-6" data-line-number="6">bom &lt;-<span class="st"> </span>scriptures <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2-7" data-line-number="7"><span class="st">  </span><span class="kw">filter</span>(volume_title <span class="op">==</span><span class="st"> &quot;Book of Mormon&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2-8" data-line-number="8"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">book_title =</span> <span class="kw">fct_inorder</span>(book_title))</a>
<a class="sourceLine" id="cb2-9" data-line-number="9"></a>
<a class="sourceLine" id="cb2-10" data-line-number="10"><span class="co"># Get just the OT and NT</span></a>
<a class="sourceLine" id="cb2-11" data-line-number="11">bible &lt;-<span class="st"> </span>scriptures <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2-12" data-line-number="12"><span class="st">  </span><span class="kw">filter</span>(volume_title <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Old Testament&quot;</span>, <span class="st">&quot;New Testament&quot;</span>))</a>
<a class="sourceLine" id="cb2-13" data-line-number="13"></a>
<a class="sourceLine" id="cb2-14" data-line-number="14"><span class="co"># Download 4 Dickens books</span></a>
<a class="sourceLine" id="cb2-15" data-line-number="15">dickens &lt;-<span class="st"> </span><span class="kw">gutenberg_download</span>(<span class="kw">c</span>(<span class="dv">19337</span>, <span class="dv">98</span>, <span class="dv">1400</span>, <span class="dv">766</span>),</a>
<a class="sourceLine" id="cb2-16" data-line-number="16">                              <span class="dt">meta_fields =</span> <span class="st">&quot;title&quot;</span>)</a>
<a class="sourceLine" id="cb2-17" data-line-number="17"></a>
<a class="sourceLine" id="cb2-18" data-line-number="18"><span class="co"># Load the pre-parts-of-speechified BoM so you don&#39;t have to run the tagger yourself</span></a>
<a class="sourceLine" id="cb2-19" data-line-number="19">bom_annotated &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data/bom_annotated.csv&quot;</span>)</a></code></pre></div>
<h3 id="part-of-speech-tagging">Part-of-speech tagging</h3>
<p>When you first work with text in R, R has no way of knowing if words are nouns, verbs, or adjectives. You can algorithmically predict what part of speech each word is using a part-of-speech tagger, like <a href="https://spacy.io/"><code>spaCy</code></a> or <a href="https://nlp.stanford.edu/">Stanford NLP</a>. You can do this in R with the <a href="https://statsmaths.github.io/cleanNLP/"><code>cleanNLP</code> package</a>, which connects to external natural language processing algorithms like spaCy or Stanford’s thing.</p>
<p>Installing <code>cleanNLP</code> is trivial—it’s just a normal R package, so use the “Packages” panel in RStudio—but connecting it with external NLP algorithms is a little trickier. To install spaCy, which is a really fast tagging library, do this:</p>
<ol style="list-style-type: decimal">
<li>Make sure Python is installed (it is if you’re on macOS or Linux; good luck with Windows—I have no idea how to install this stuff there, but there’s a way).</li>
<li><p>Open Terminal and run this command to install <code>spaCy</code>:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode sh"><code class="sourceCode bash"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="ex">pip</span> install -U spacy</a></code></pre></div></li>
<li><p>Run this command to download <code>spaCy</code>’s English algorithms:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode sh"><code class="sourceCode bash"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="ex">python</span> -m spacy download en</a></code></pre></div></li>
<li><p>The end!</p></li>
</ol>
<p>Here’s the general process for tagging (they call it annotating) text:</p>
<ol style="list-style-type: decimal">
<li>Make a dataset where the first column is the id (line number, chapter number, book+chapter, whatever) and the second column is the text itself.</li>
<li>Initialize the NLP tagger. You can use an R-only one that doesn’t need Python or any other external dependencies with <code>cnlp_init_udpipe()</code>. If you’ve installed spaCy, use <code>cnlp_init_spacy()</code>. If you’ve installed Stanford’s thing, use <code>cnlp_init_corenlp()</code>.</li>
<li>Feed the data frame from step 1 into the <code>cnlp_annotate()</code> function and wait.</li>
<li>Save the tagged data as a file on your computer so you don’t have to retag it every time. Use <code>cnlp_get_tif() %&gt;% write_csv()</code>.</li>
<li>The end!</li>
</ol>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="co"># Wrangle BoM text into format that cnlp_annotate() needs</span></a>
<a class="sourceLine" id="cb5-2" data-line-number="2">bom_chapters &lt;-<span class="st"> </span>bom <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb5-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">book_chapter =</span> <span class="kw">paste</span>(book_title, chapter_number)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb5-4" data-line-number="4"><span class="st">  </span><span class="kw">select</span>(book_title, book_chapter, scripture_text) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb5-5" data-line-number="5"><span class="st">  </span><span class="kw">nest</span>(scripture_text) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb5-6" data-line-number="6"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">text =</span> data <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">map_chr</span>(<span class="op">~</span><span class="st"> </span><span class="kw">paste</span>(.<span class="op">$</span>scripture_text, <span class="dt">collapse =</span> <span class="st">&quot; &quot;</span>))) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb5-7" data-line-number="7"><span class="st">  </span><span class="kw">select</span>(book_chapter, text, book_title)</a>
<a class="sourceLine" id="cb5-8" data-line-number="8"></a>
<a class="sourceLine" id="cb5-9" data-line-number="9"><span class="co"># Set up NLP backend</span></a>
<a class="sourceLine" id="cb5-10" data-line-number="10"><span class="co"># cnlp_init_udpipe()  # This NLP engine doesn&#39;t need Python, but it&#39;s so so so slow</span></a>
<a class="sourceLine" id="cb5-11" data-line-number="11"><span class="kw">cnlp_init_spacy</span>()  <span class="co"># Use spaCy</span></a>
<a class="sourceLine" id="cb5-12" data-line-number="12"></a>
<a class="sourceLine" id="cb5-13" data-line-number="13"><span class="co"># Tag all the parts of speech!</span></a>
<a class="sourceLine" id="cb5-14" data-line-number="14">bom_annotated &lt;-<span class="st"> </span><span class="kw">cnlp_annotate</span>(bom_chapters, <span class="dt">as_strings =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb5-15" data-line-number="15"></a>
<a class="sourceLine" id="cb5-16" data-line-number="16"><span class="co"># Save the tagged data so we don&#39;t have to tag it all again</span></a>
<a class="sourceLine" id="cb5-17" data-line-number="17"><span class="kw">cnlp_get_tif</span>(bom_annotated) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb5-18" data-line-number="18"><span class="st">  </span><span class="kw">write_csv</span>(<span class="dt">path =</span> <span class="st">&quot;data/bom_annotated.csv&quot;</span>)</a></code></pre></div>
<h3 id="tokens-and-word-counts">Tokens and word counts</h3>
<h4 id="single-words">Single words</h4>
<p>Now that we have tidy text, we can start counting words. Here’s what’s happening below:</p>
<ul>
<li>We use <code>unnest_tokens()</code> to split each verse (in this case each row is a verse; that’s not always the case, though—sometimes it’ll be chapters or lines or entire books) into separate words.</li>
<li>We use <code>anti_join()</code> to remove all the common stop words like “a” and “the”. You can do the same thing with <code>filter()</code> like so: <code>filter(!(word %in% stop_words$word))</code> (I prefer this way, actually)</li>
<li>We count how many times each word appears and sort the list</li>
<li>We keep just the top 15 words</li>
<li>We plot it with <code>geom_col()</code></li>
</ul>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1">bom_words &lt;-<span class="st"> </span>bom <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb6-2" data-line-number="2"><span class="st">  </span><span class="kw">unnest_tokens</span>(word, scripture_text) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb6-3" data-line-number="3"><span class="st">  </span><span class="kw">anti_join</span>(stop_words) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb6-4" data-line-number="4"><span class="st">  </span><span class="co"># count(book_title, word, sort = TRUE)</span></a>
<a class="sourceLine" id="cb6-5" data-line-number="5"><span class="st">  </span><span class="kw">count</span>(word, <span class="dt">sort =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb6-6" data-line-number="6"><span class="st">  </span><span class="kw">top_n</span>(<span class="dv">15</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb6-7" data-line-number="7"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">word =</span> <span class="kw">fct_inorder</span>(word))</a>
<a class="sourceLine" id="cb6-8" data-line-number="8"></a>
<a class="sourceLine" id="cb6-9" data-line-number="9"><span class="kw">ggplot</span>(bom_words, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">fct_rev</span>(word), <span class="dt">y =</span> n)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb6-10" data-line-number="10"><span class="st">  </span><span class="kw">geom_col</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb6-11" data-line-number="11"><span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb6-12" data-line-number="12"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">labels =</span> scales<span class="op">::</span>comma) <span class="op">+</span></a>
<a class="sourceLine" id="cb6-13" data-line-number="13"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;Count&quot;</span>, <span class="dt">x =</span> <span class="ot">NULL</span>, <span class="dt">title =</span> <span class="st">&quot;15 most frequent words in the Book of Mormon&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb6-14" data-line-number="14"><span class="st">  </span><span class="kw">theme_minimal</span>()</a></code></pre></div>
<p><img src="/class/11-class_files/figure-html/bom-single-words-1.png" width="672" /></p>
<h4 id="bigrams">Bigrams</h4>
<p>We can also look at the frequency of pairs of words. First we’ll look at common bigrams, filtering out stop words again (since we don’t want things like “of the” and “in the”):</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1">bom_bigrams &lt;-<span class="st"> </span>bom <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb7-2" data-line-number="2"><span class="st">  </span><span class="kw">unnest_tokens</span>(bigram, scripture_text, <span class="dt">token =</span> <span class="st">&quot;ngrams&quot;</span>, <span class="dt">n =</span> <span class="dv">2</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb7-3" data-line-number="3"><span class="st">  </span><span class="co"># Split the bigram column into two columns</span></a>
<a class="sourceLine" id="cb7-4" data-line-number="4"><span class="st">  </span><span class="kw">separate</span>(bigram, <span class="kw">c</span>(<span class="st">&quot;word1&quot;</span>, <span class="st">&quot;word2&quot;</span>), <span class="dt">sep =</span> <span class="st">&quot; &quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb7-5" data-line-number="5"><span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span>word1 <span class="op">%in%</span><span class="st"> </span>stop_words<span class="op">$</span>word,</a>
<a class="sourceLine" id="cb7-6" data-line-number="6">         <span class="op">!</span>word2 <span class="op">%in%</span><span class="st"> </span>stop_words<span class="op">$</span>word) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb7-7" data-line-number="7"><span class="st">  </span><span class="co"># Put the two word columns back together</span></a>
<a class="sourceLine" id="cb7-8" data-line-number="8"><span class="st">  </span><span class="kw">unite</span>(bigram, word1, word2, <span class="dt">sep =</span> <span class="st">&quot; &quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb7-9" data-line-number="9"><span class="st">  </span><span class="kw">count</span>(bigram, <span class="dt">sort =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb7-10" data-line-number="10"><span class="st">  </span><span class="kw">top_n</span>(<span class="dv">10</span>)</a>
<a class="sourceLine" id="cb7-11" data-line-number="11"></a>
<a class="sourceLine" id="cb7-12" data-line-number="12"><span class="co"># We could plot this bom_bigrams object with geom_col(), but I&#39;ll skip that part</span></a>
<a class="sourceLine" id="cb7-13" data-line-number="13"><span class="co"># Here&#39;s what this looks like:</span></a>
<a class="sourceLine" id="cb7-14" data-line-number="14">bom_bigrams</a></code></pre></div>
<pre><code>## # A tibble: 10 x 2
##    bigram               n
##    &lt;chr&gt;            &lt;int&gt;
##  1 thou hast          127
##  2 lord god           115
##  3 holy ghost          94
##  4 thou shalt          94
##  5 lord hath           67
##  6 jesus christ        66
##  7 beloved brethren    65
##  8 thou art            57
##  9 judgment seat       54
## 10 behold ye           49</code></pre>
<h4 id="bigrams-and-probability">Bigrams and probability</h4>
<p>We can replicate the <a href="https://pudding.cool/2017/08/screen-direction/">“She Giggles, He Gallops”</a> idea by counting the bigrams that match “he X” and “she X”.</p>
<p>The log ratio idea shows how much more likely a word is compared to its counterpart (so “she fled” is more than 4x more likely to appear than “he fled”. In this graph, I replaced the x-axis labels with “2x” and “4x”, but without those, you get numbers like 1, 2, and 3 (or -1, -2, -3)). To convert those logged ratio numbers into the multiplicative version (i.e. 2x instead of 1), raise 2 to the power of the log ratio. If the log ratio is 3, the human-readable version is <span class="math inline">\(2^3\)</span>, or 8 times.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1"><span class="co"># Take the log of 8:</span></a>
<a class="sourceLine" id="cb9-2" data-line-number="2"><span class="kw">log2</span>(<span class="dv">8</span>)</a></code></pre></div>
<pre><code>## [1] 3</code></pre>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1"><span class="co"># Reverse log of 3:</span></a>
<a class="sourceLine" id="cb11-2" data-line-number="2"><span class="dv">2</span><span class="op">^</span><span class="dv">3</span></a></code></pre></div>
<pre><code>## [1] 8</code></pre>
<p>The only text wizardry here is tokenizing the words. Pretty much the rest of all this code is just <code>dplyr</code> mutating, filtering, and counting:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" data-line-number="1">pronouns &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;he&quot;</span>, <span class="st">&quot;she&quot;</span>)</a>
<a class="sourceLine" id="cb13-2" data-line-number="2"></a>
<a class="sourceLine" id="cb13-3" data-line-number="3">bigram_he_she_counts &lt;-<span class="st"> </span>bom <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb13-4" data-line-number="4"><span class="st">  </span><span class="kw">unnest_tokens</span>(bigram, scripture_text, <span class="dt">token =</span> <span class="st">&quot;ngrams&quot;</span>, <span class="dt">n =</span> <span class="dv">2</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb13-5" data-line-number="5"><span class="st">  </span><span class="kw">count</span>(bigram, <span class="dt">sort =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb13-6" data-line-number="6"><span class="st">  </span><span class="co"># Split the bigram column into two columns</span></a>
<a class="sourceLine" id="cb13-7" data-line-number="7"><span class="st">  </span><span class="kw">separate</span>(bigram, <span class="kw">c</span>(<span class="st">&quot;word1&quot;</span>, <span class="st">&quot;word2&quot;</span>), <span class="dt">sep =</span> <span class="st">&quot; &quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb13-8" data-line-number="8"><span class="st">  </span><span class="co"># Only choose rows where the first word is he or she</span></a>
<a class="sourceLine" id="cb13-9" data-line-number="9"><span class="st">  </span><span class="kw">filter</span>(word1 <span class="op">%in%</span><span class="st"> </span>pronouns) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb13-10" data-line-number="10"><span class="st">  </span><span class="kw">count</span>(word1, word2, <span class="dt">wt =</span> n, <span class="dt">sort =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb13-11" data-line-number="11"><span class="st">  </span><span class="kw">rename</span>(<span class="dt">total =</span> nn)</a>
<a class="sourceLine" id="cb13-12" data-line-number="12"></a>
<a class="sourceLine" id="cb13-13" data-line-number="13">word_ratios &lt;-<span class="st"> </span>bigram_he_she_counts <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb13-14" data-line-number="14"><span class="st">  </span><span class="co"># Look at each of the second words</span></a>
<a class="sourceLine" id="cb13-15" data-line-number="15"><span class="st">  </span><span class="kw">group_by</span>(word2) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb13-16" data-line-number="16"><span class="st">  </span><span class="co"># Only choose rows where the second word appears more than 10 times</span></a>
<a class="sourceLine" id="cb13-17" data-line-number="17"><span class="st">  </span><span class="kw">filter</span>(<span class="kw">sum</span>(total) <span class="op">&gt;</span><span class="st"> </span><span class="dv">10</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb13-18" data-line-number="18"><span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb13-19" data-line-number="19"><span class="st">  </span><span class="co"># Spread out the word1 column so that there&#39;s a column named &quot;he&quot; and one named &quot;she&quot;</span></a>
<a class="sourceLine" id="cb13-20" data-line-number="20"><span class="st">  </span><span class="kw">spread</span>(word1, total, <span class="dt">fill =</span> <span class="dv">0</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb13-21" data-line-number="21"><span class="st">  </span><span class="co"># Add 1 to each number so that logs work (just in case any are zero)</span></a>
<a class="sourceLine" id="cb13-22" data-line-number="22"><span class="st">  </span><span class="kw">mutate_if</span>(is.numeric, <span class="kw">funs</span>((. <span class="op">+</span><span class="st"> </span><span class="dv">1</span>) <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(. <span class="op">+</span><span class="st"> </span><span class="dv">1</span>))) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb13-23" data-line-number="23"><span class="st">  </span><span class="co"># Create a new column that is the logged ratio of the she counts to he counts</span></a>
<a class="sourceLine" id="cb13-24" data-line-number="24"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">logratio =</span> <span class="kw">log2</span>(she <span class="op">/</span><span class="st"> </span>he)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb13-25" data-line-number="25"><span class="st">  </span><span class="co"># Sort by that ratio</span></a>
<a class="sourceLine" id="cb13-26" data-line-number="26"><span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(logratio))</a>
<a class="sourceLine" id="cb13-27" data-line-number="27"></a>
<a class="sourceLine" id="cb13-28" data-line-number="28"><span class="co"># Rearrange this data so it&#39;s plottable</span></a>
<a class="sourceLine" id="cb13-29" data-line-number="29">plot_word_ratios &lt;-<span class="st"> </span>word_ratios <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb13-30" data-line-number="30"><span class="st">  </span><span class="co"># This gets the words in the right order---we take the absolute value, select</span></a>
<a class="sourceLine" id="cb13-31" data-line-number="31"><span class="st">  </span><span class="co"># only rows where the log ratio is bigger than 0, and then take the top 15 words</span></a>
<a class="sourceLine" id="cb13-32" data-line-number="32"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">abslogratio =</span> <span class="kw">abs</span>(logratio)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb13-33" data-line-number="33"><span class="st">  </span><span class="kw">group_by</span>(logratio <span class="op">&lt;</span><span class="st"> </span><span class="dv">0</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb13-34" data-line-number="34"><span class="st">  </span><span class="kw">top_n</span>(<span class="dv">15</span>, abslogratio) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb13-35" data-line-number="35"><span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb13-36" data-line-number="36"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">word =</span> <span class="kw">reorder</span>(word2, logratio)) </a>
<a class="sourceLine" id="cb13-37" data-line-number="37"></a>
<a class="sourceLine" id="cb13-38" data-line-number="38"><span class="co"># Finally we plot this</span></a>
<a class="sourceLine" id="cb13-39" data-line-number="39"><span class="kw">ggplot</span>(plot_word_ratios, <span class="kw">aes</span>(word, logratio, <span class="dt">color =</span> logratio <span class="op">&lt;</span><span class="st"> </span><span class="dv">0</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb13-40" data-line-number="40"><span class="st">  </span><span class="kw">geom_segment</span>(<span class="kw">aes</span>(<span class="dt">x =</span> word, <span class="dt">xend =</span> word,</a>
<a class="sourceLine" id="cb13-41" data-line-number="41">                   <span class="dt">y =</span> <span class="dv">0</span>, <span class="dt">yend =</span> logratio), </a>
<a class="sourceLine" id="cb13-42" data-line-number="42">               <span class="dt">size =</span> <span class="fl">1.1</span>, <span class="dt">alpha =</span> <span class="fl">0.6</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb13-43" data-line-number="43"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="fl">3.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb13-44" data-line-number="44"><span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb13-45" data-line-number="45"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;How much more/less likely&quot;</span>, <span class="dt">x =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb13-46" data-line-number="46"><span class="st">  </span><span class="kw">scale_color_discrete</span>(<span class="dt">name =</span> <span class="st">&quot;&quot;</span>, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;More &#39;she&#39;&quot;</span>, <span class="st">&quot;More &#39;he&#39;&quot;</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb13-47" data-line-number="47"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>),</a>
<a class="sourceLine" id="cb13-48" data-line-number="48">                     <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;8x&quot;</span>, <span class="st">&quot;4x&quot;</span>, <span class="st">&quot;2x&quot;</span>,</a>
<a class="sourceLine" id="cb13-49" data-line-number="49">                                <span class="st">&quot;Same&quot;</span>, <span class="st">&quot;2x&quot;</span>, <span class="st">&quot;4x&quot;</span>, <span class="st">&quot;8x&quot;</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb13-50" data-line-number="50"><span class="st">  </span><span class="kw">theme_minimal</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb13-51" data-line-number="51"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;bottom&quot;</span>)</a></code></pre></div>
<p><img src="/class/11-class_files/figure-html/bigrams-he-she-1.png" width="672" /></p>
<h3 id="sentiment-analysis">Sentiment analysis</h3>
<p>At its core, sentiment analysis involves looking at a big list of words for how negative or positive they are. Some sentiment dictionaries mark if a word is “negative” or “positive”; some give words a score from -3 to 3; some give different emotions like “sadness” or “anger”. You can see what the different dictionaries look like with <code>get_sentiments()</code></p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1"><span class="kw">get_sentiments</span>(<span class="st">&quot;afinn&quot;</span>)  <span class="co"># Scoring system</span></a></code></pre></div>
<pre><code>## # A tibble: 2,476 x 2
##    word       score
##    &lt;chr&gt;      &lt;int&gt;
##  1 abandon       -2
##  2 abandoned     -2
##  3 abandons      -2
##  4 abducted      -2
##  5 abduction     -2
##  6 abductions    -2
##  7 abhor         -3
##  8 abhorred      -3
##  9 abhorrent     -3
## 10 abhors        -3
## # ... with 2,466 more rows</code></pre>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1"><span class="co"># get_sentiments(&quot;bing&quot;)  # Negative/positive</span></a>
<a class="sourceLine" id="cb16-2" data-line-number="2"><span class="co"># get_sentiments(&quot;nrc&quot;)  # Specific emotions</span></a>
<a class="sourceLine" id="cb16-3" data-line-number="3"><span class="co"># get_sentiments(&quot;loughran&quot;)  # Designed for financial statements; positive/negative</span></a></code></pre></div>
<p>Here we split the book of Alma into words, join a sentiment dictionary to it, and use dplyr data wrangling to calculate the net number positive words in each chapter. Had we used the AFINN library, we could calculate the average sentiment per chapter, since AFINN uses a scoring system instead of negative/positive labels.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" data-line-number="1">alma_sentiment &lt;-<span class="st"> </span>bom <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb17-2" data-line-number="2"><span class="st">  </span><span class="co"># Only look at Alma</span></a>
<a class="sourceLine" id="cb17-3" data-line-number="3"><span class="st">  </span><span class="kw">filter</span>(book_title <span class="op">==</span><span class="st"> &quot;Alma&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb17-4" data-line-number="4"><span class="st">  </span><span class="co"># Split into individual words</span></a>
<a class="sourceLine" id="cb17-5" data-line-number="5"><span class="st">  </span><span class="kw">unnest_tokens</span>(word, scripture_text) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb17-6" data-line-number="6"><span class="st">  </span><span class="co"># Join bing sentiment dicionary</span></a>
<a class="sourceLine" id="cb17-7" data-line-number="7"><span class="st">  </span><span class="kw">inner_join</span>(<span class="kw">get_sentiments</span>(<span class="st">&quot;bing&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb17-8" data-line-number="8"><span class="st">  </span><span class="co"># Count how many postive/negative words are in each chapter</span></a>
<a class="sourceLine" id="cb17-9" data-line-number="9"><span class="st">  </span><span class="kw">count</span>(chapter_number, sentiment) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb17-10" data-line-number="10"><span class="st">  </span><span class="co"># Spread the count into two columns named positive and negative</span></a>
<a class="sourceLine" id="cb17-11" data-line-number="11"><span class="st">  </span><span class="kw">spread</span>(sentiment, n, <span class="dt">fill =</span> <span class="dv">0</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb17-12" data-line-number="12"><span class="st">  </span><span class="co"># Subtract the positive words from the negative words</span></a>
<a class="sourceLine" id="cb17-13" data-line-number="13"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">net_sentiment =</span> positive <span class="op">-</span><span class="st"> </span>negative)</a>
<a class="sourceLine" id="cb17-14" data-line-number="14"></a>
<a class="sourceLine" id="cb17-15" data-line-number="15"><span class="co"># Plot this puppy</span></a>
<a class="sourceLine" id="cb17-16" data-line-number="16"><span class="kw">ggplot</span>(alma_sentiment, </a>
<a class="sourceLine" id="cb17-17" data-line-number="17">       <span class="kw">aes</span>(<span class="dt">x =</span> chapter_number, <span class="dt">y =</span> net_sentiment, <span class="dt">fill =</span> net_sentiment <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb17-18" data-line-number="18"><span class="st">  </span><span class="kw">geom_col</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb17-19" data-line-number="19"><span class="st">  </span><span class="kw">guides</span>(<span class="dt">fill =</span> <span class="ot">FALSE</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb17-20" data-line-number="20"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Chapter&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Net sentiment&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb17-21" data-line-number="21"><span class="st">  </span><span class="kw">theme_minimal</span>()</a></code></pre></div>
<p><img src="/class/11-class_files/figure-html/alma-sentiment-1.png" width="672" /></p>
<h3 id="tf-idf">tf-idf</h3>
<p>We can determine which words are the most unique for each book/document in our corpus using by calculating the tf-idf (term frequency-inverse document frequency) score for each term. The tf-idf is the product of the term frequency and the inverse document frequency:</p>
<p><span class="math display">\[
\begin{aligned}
tf(\text{term}) &amp;= \frac{n_{\text{term}}}{n_{\text{terms in document}}} \\
idf(\text{term}) &amp;= \ln{\left(\frac{n_{\text{documents}}}{n_{\text{documents containing term}}}\right)} \\
tf\text{-}idf(\text{term}) &amp;= tf(\text{term}) \times idf(\text{term})
\end{aligned}
\]</span></p>
<p>Fortunately you don’t need to remember that formula. The <code>bind_tf_idf()</code> function will calculate this for you. Remember, the higher the tf-idf number, the more unique the term is in the document, but these numbers are meaningless and unitless—you can’t convert them to a percentage or anything.</p>
<p>For the sake of space, here are the most unique words in the 4 books of Nephi (I don’t want to try to fit 15 facets on this website)</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" data-line-number="1"><span class="co"># Get a list of words in all the books</span></a>
<a class="sourceLine" id="cb18-2" data-line-number="2">bom_words &lt;-<span class="st"> </span>bom <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb18-3" data-line-number="3"><span class="st">  </span><span class="kw">unnest_tokens</span>(word, scripture_text) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb18-4" data-line-number="4"><span class="st">  </span><span class="kw">count</span>(book_title, word, <span class="dt">sort =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb18-5" data-line-number="5"><span class="st">  </span><span class="kw">ungroup</span>()</a>
<a class="sourceLine" id="cb18-6" data-line-number="6"></a>
<a class="sourceLine" id="cb18-7" data-line-number="7"><span class="co"># Add the tf-idf for these words</span></a>
<a class="sourceLine" id="cb18-8" data-line-number="8">bom_tf_idf &lt;-<span class="st"> </span>bom_words <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb18-9" data-line-number="9"><span class="st">  </span><span class="kw">bind_tf_idf</span>(word, book_title, n) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb18-10" data-line-number="10"><span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(tf_idf))</a>
<a class="sourceLine" id="cb18-11" data-line-number="11"></a>
<a class="sourceLine" id="cb18-12" data-line-number="12"><span class="co"># Get the top 10 uniquest words in just the Nephi books</span></a>
<a class="sourceLine" id="cb18-13" data-line-number="13">bom_tf_idf_plot &lt;-<span class="st"> </span>bom_tf_idf <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb18-14" data-line-number="14"><span class="st">  </span><span class="kw">filter</span>(<span class="kw">str_detect</span>(book_title, <span class="st">&quot;Nephi&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb18-15" data-line-number="15"><span class="st">  </span><span class="kw">group_by</span>(book_title) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb18-16" data-line-number="16"><span class="st">  </span><span class="kw">top_n</span>(<span class="dv">10</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb18-17" data-line-number="17"><span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb18-18" data-line-number="18"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">word =</span> <span class="kw">fct_inorder</span>(word))</a>
<a class="sourceLine" id="cb18-19" data-line-number="19"></a>
<a class="sourceLine" id="cb18-20" data-line-number="20"><span class="kw">ggplot</span>(bom_tf_idf_plot, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">fct_rev</span>(word), <span class="dt">y =</span> tf_idf, <span class="dt">fill =</span> book_title)) <span class="op">+</span></a>
<a class="sourceLine" id="cb18-21" data-line-number="21"><span class="st">  </span><span class="kw">geom_col</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb18-22" data-line-number="22"><span class="st">  </span><span class="kw">guides</span>(<span class="dt">fill =</span> <span class="ot">FALSE</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb18-23" data-line-number="23"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;tf-idf&quot;</span>, <span class="dt">x =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb18-24" data-line-number="24"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>book_title, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb18-25" data-line-number="25"><span class="st">  </span><span class="kw">theme_minimal</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb18-26" data-line-number="26"><span class="st">  </span><span class="kw">coord_flip</span>()</a></code></pre></div>
<p><img src="/class/11-class_files/figure-html/nephi-tf-idf-1.png" width="672" /></p>
<h3 id="topic-modeling">Topic modeling</h3>
<p>With topic modeling, we go beyond just counting words and we do some cool unsupervised Bayesian machine learning to find a number of clusters of words that tend to hang together.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" data-line-number="1">dickens_dtm &lt;-<span class="st"> </span>dickens <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb19-2" data-line-number="2"><span class="st">  </span><span class="kw">unnest_tokens</span>(word, text) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb19-3" data-line-number="3"><span class="st">  </span><span class="co"># Get rid of stop words</span></a>
<a class="sourceLine" id="cb19-4" data-line-number="4"><span class="st">  </span><span class="kw">anti_join</span>(stop_words) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb19-5" data-line-number="5"><span class="st">  </span><span class="kw">count</span>(title, word, <span class="dt">sort =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb19-6" data-line-number="6"><span class="st">  </span><span class="co"># Convert this to a document-term matrix (a strange data format that LDA nees to work)</span></a>
<a class="sourceLine" id="cb19-7" data-line-number="7"><span class="st">  </span><span class="kw">cast_dtm</span>(title, word, n)</a>
<a class="sourceLine" id="cb19-8" data-line-number="8"></a>
<a class="sourceLine" id="cb19-9" data-line-number="9"><span class="co"># Find 10 topics (or clusters of words)</span></a>
<a class="sourceLine" id="cb19-10" data-line-number="10">dickens_lda &lt;-<span class="st"> </span><span class="kw">LDA</span>(dickens_dtm, <span class="dt">k =</span> <span class="dv">10</span>, <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">seed =</span> <span class="dv">1234</span>))</a>
<a class="sourceLine" id="cb19-11" data-line-number="11"></a>
<a class="sourceLine" id="cb19-12" data-line-number="12"><span class="co"># Convert the LDA object into a data frame that we can work with</span></a>
<a class="sourceLine" id="cb19-13" data-line-number="13"><span class="co"># The beta column is essentially a measure of word importance within the</span></a>
<a class="sourceLine" id="cb19-14" data-line-number="14"><span class="co"># topic---the higher the number, the more important the word is in the topic</span></a>
<a class="sourceLine" id="cb19-15" data-line-number="15">dickens_topics &lt;-<span class="st"> </span><span class="kw">tidy</span>(dickens_lda, <span class="dt">matrix =</span> <span class="st">&quot;beta&quot;</span>)</a></code></pre></div>
<p>The algorithm finds 10 clusters of words that should be statistically meaningful. In real life, you’d need to determine how these words are related and give them a human-readable name.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" data-line-number="1"><span class="co"># Here are the most important words in each of the 10 clusters</span></a>
<a class="sourceLine" id="cb20-2" data-line-number="2">dickens_top_terms &lt;-<span class="st"> </span>dickens_topics <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb20-3" data-line-number="3"><span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span><span class="kw">is.na</span>(term)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb20-4" data-line-number="4"><span class="st">  </span><span class="kw">group_by</span>(topic) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb20-5" data-line-number="5"><span class="st">  </span><span class="kw">top_n</span>(<span class="dv">10</span>, beta) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb20-6" data-line-number="6"><span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb20-7" data-line-number="7"><span class="st">  </span><span class="kw">arrange</span>(topic, <span class="op">-</span>beta)</a>
<a class="sourceLine" id="cb20-8" data-line-number="8"></a>
<a class="sourceLine" id="cb20-9" data-line-number="9"><span class="co"># Make a comma separated list of the top 10 terms in each topic</span></a>
<a class="sourceLine" id="cb20-10" data-line-number="10">dickens_top_terms <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb20-11" data-line-number="11"><span class="st">  </span><span class="kw">group_by</span>(topic) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb20-12" data-line-number="12"><span class="st">  </span><span class="kw">nest</span>(term) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb20-13" data-line-number="13"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">words =</span> data <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">map_chr</span>(<span class="op">~</span><span class="st"> </span><span class="kw">paste</span>(.<span class="op">$</span>term, <span class="dt">collapse =</span> <span class="st">&quot;, &quot;</span>))) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb20-14" data-line-number="14"><span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>data) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb20-15" data-line-number="15"><span class="st">  </span>pander<span class="op">::</span><span class="kw">pandoc.table</span>()</a></code></pre></div>
<table style="width:57%;">
<colgroup>
<col width="11%" />
<col width="45%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">topic</th>
<th align="center">words</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">time, copperfield, home, dear,
mind, peggotty, half, mother,
aunt, day</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">time, house, head, hand, miss,
returned, night, door,
pumblechook, day</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">defarge, lorry, miss, time,
madame, hand, night, doctor,
manette, pross</td>
</tr>
<tr class="even">
<td align="center">4</td>
<td align="center">hand, house, dear, hands,
night, looked, sir, business,
head, returned</td>
</tr>
<tr class="odd">
<td align="center">5</td>
<td align="center">scrooge, christmas, ghost,
spirit, time, cried, bob,
scrooge’s, door, hand</td>
</tr>
<tr class="even">
<td align="center">6</td>
<td align="center">peggotty, micawber, aunt,
miss, time, traddles, agnes,
copperfield, dora, mother</td>
</tr>
<tr class="odd">
<td align="center">7</td>
<td align="center">time, micawber, dear, aunt,
traddles, miss, night,
steerforth, murdstone, hand</td>
</tr>
<tr class="even">
<td align="center">8</td>
<td align="center">lorry, head, sir, father,
looked, hand, day, door,
tellson’s, red</td>
</tr>
<tr class="odd">
<td align="center">9</td>
<td align="center">joe, pip, looked, herbert,
wemmick, miss, havisham,
estella, jaggers, biddy</td>
</tr>
<tr class="even">
<td align="center">10</td>
<td align="center">peggotty, returned, miss,
aunt, house, micawber, dear,
head, agnes, eyes</td>
</tr>
</tbody>
</table>
<p>And here are those 10 topics graphed:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" data-line-number="1">dickens_top_terms <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb21-2" data-line-number="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">term =</span> <span class="kw">reorder</span>(term, beta)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb21-3" data-line-number="3"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(term, beta, <span class="dt">fill =</span> <span class="kw">factor</span>(topic))) <span class="op">+</span></a>
<a class="sourceLine" id="cb21-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">show.legend =</span> <span class="ot">FALSE</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb21-5" data-line-number="5"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="ot">NULL</span>, <span class="dt">y =</span> <span class="st">&quot;LDA beta (word importance in topic)&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb21-6" data-line-number="6"><span class="st">  </span><span class="kw">theme_minimal</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb21-7" data-line-number="7"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>topic, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb21-8" data-line-number="8"><span class="st">  </span><span class="kw">coord_flip</span>()</a></code></pre></div>
<p><img src="/class/11-class_files/figure-html/plot-top-lda-terms-1.png" width="672" /></p>
<h3 id="fingerprinting">Fingerprinting</h3>
<h4 id="hapax-legomena">Hapax legomena</h4>
<p>Finally, we can do some document fingerprinting based on specific text characteristics. First, we’ll look at how often each chapter in the Book of Mormon uses hapax legomena (words that appear only once).</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb22-1" data-line-number="1"><span class="co"># Count the words in the BoM; make a new variable named hapax that is true if</span></a>
<a class="sourceLine" id="cb22-2" data-line-number="2"><span class="co"># the word only appears once</span></a>
<a class="sourceLine" id="cb22-3" data-line-number="3">bom_words &lt;-<span class="st"> </span>bom <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb22-4" data-line-number="4"><span class="st">  </span><span class="kw">unnest_tokens</span>(word, scripture_text) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb22-5" data-line-number="5"><span class="st">  </span><span class="kw">count</span>(word, <span class="dt">sort =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb22-6" data-line-number="6"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">hapax =</span> n <span class="op">==</span><span class="st"> </span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb22-7" data-line-number="7"></a>
<a class="sourceLine" id="cb22-8" data-line-number="8"><span class="co"># Make a lookup table of BoM chapters. This is helpful because we need to</span></a>
<a class="sourceLine" id="cb22-9" data-line-number="9"><span class="co"># combine book names and chapter numbers to get unique hapaxes in each</span></a>
<a class="sourceLine" id="cb22-10" data-line-number="10"><span class="co"># book+chapter combination, but then when we plot the results, we still need</span></a>
<a class="sourceLine" id="cb22-11" data-line-number="11"><span class="co"># individual non-combined columns for chapter numbers and book names. This makes</span></a>
<a class="sourceLine" id="cb22-12" data-line-number="12"><span class="co"># a small data frame of book titles, chapter numbers, and combined book+chapter</span></a>
<a class="sourceLine" id="cb22-13" data-line-number="13">bom_lookup &lt;-<span class="st"> </span>bom <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb22-14" data-line-number="14"><span class="st">  </span><span class="kw">distinct</span>(book_title, chapter_number) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb22-15" data-line-number="15"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">book_chapter =</span> <span class="kw">paste0</span>(book_title, <span class="st">&quot; &quot;</span>, chapter_number),</a>
<a class="sourceLine" id="cb22-16" data-line-number="16">         <span class="dt">book_title =</span> <span class="kw">as.character</span>(book_title)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb22-17" data-line-number="17"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">chapter_number =</span> <span class="kw">str_remove</span>(book_chapter, book_title),</a>
<a class="sourceLine" id="cb22-18" data-line-number="18">         <span class="dt">chapter_number =</span> <span class="kw">as.integer</span>(chapter_number)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb22-19" data-line-number="19"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">book_title =</span> <span class="kw">fct_inorder</span>(book_title))</a>
<a class="sourceLine" id="cb22-20" data-line-number="20"></a>
<a class="sourceLine" id="cb22-21" data-line-number="21"><span class="co"># Calculate how many hapaxes appear in each chapter of the BoM</span></a>
<a class="sourceLine" id="cb22-22" data-line-number="22">bom_hapax &lt;-<span class="st"> </span>bom <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb22-23" data-line-number="23"><span class="st">  </span><span class="kw">unnest_tokens</span>(word, scripture_text) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb22-24" data-line-number="24"><span class="st">  </span><span class="kw">left_join</span>(bom_words, <span class="dt">by =</span> <span class="st">&quot;word&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb22-25" data-line-number="25"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">book_chapter =</span> <span class="kw">paste0</span>(book_title, <span class="st">&quot; &quot;</span>, chapter_number)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb22-26" data-line-number="26"><span class="st">  </span><span class="kw">group_by</span>(book_chapter) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb22-27" data-line-number="27"><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">num_words =</span> <span class="kw">n</span>(),</a>
<a class="sourceLine" id="cb22-28" data-line-number="28">            <span class="dt">num_hapax =</span> <span class="kw">sum</span>(hapax, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb22-29" data-line-number="29"><span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb22-30" data-line-number="30"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prop_hapax =</span> num_hapax <span class="op">/</span><span class="st"> </span>num_words) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb22-31" data-line-number="31"><span class="st">  </span><span class="kw">left_join</span>(bom_lookup, <span class="dt">by =</span> <span class="st">&quot;book_chapter&quot;</span>)</a></code></pre></div>
<p>As you can see in the plot, the Isaiah chapters in 2 and 3 Nephi use a surprising number of hapaxes, indicating that they probably come from a different author.</p>
<figure class="fullwidth">
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb23-1" data-line-number="1"><span class="co"># Plot this</span></a>
<a class="sourceLine" id="cb23-2" data-line-number="2"><span class="kw">ggplot</span>(bom_hapax, <span class="kw">aes</span>(<span class="dt">x =</span> chapter_number, <span class="dt">y =</span> <span class="kw">fct_rev</span>(book_title), <span class="dt">fill =</span> prop_hapax)) <span class="op">+</span></a>
<a class="sourceLine" id="cb23-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_tile</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb23-4" data-line-number="4"><span class="st">  </span><span class="kw">scale_fill_viridis_c</span>(<span class="dt">option =</span> <span class="st">&quot;plasma&quot;</span>, <span class="dt">labels =</span> scales<span class="op">::</span><span class="kw">percent_format</span>(<span class="dt">accuracy =</span> <span class="dv">1</span>)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb23-5" data-line-number="5"><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">63</span>, <span class="dt">expand =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb23-6" data-line-number="6"><span class="st">  </span><span class="kw">guides</span>(<span class="dt">fill =</span> <span class="kw">guide_colorbar</span>(<span class="dt">barwidth =</span> <span class="dv">20</span>, <span class="dt">barheight =</span> <span class="fl">0.5</span>, <span class="dt">title.position =</span> <span class="st">&quot;top&quot;</span>,</a>
<a class="sourceLine" id="cb23-7" data-line-number="7">                               <span class="dt">title =</span> <span class="st">&quot;Proportion of words that are hapax legomena&quot;</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb23-8" data-line-number="8"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Chapter&quot;</span>, <span class="dt">y =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb23-9" data-line-number="9"><span class="st">  </span><span class="kw">coord_equal</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb23-10" data-line-number="10"><span class="st">  </span><span class="kw">theme_minimal</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb23-11" data-line-number="11"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;bottom&quot;</span>,</a>
<a class="sourceLine" id="cb23-12" data-line-number="12">        <span class="dt">panel.grid.minor =</span> <span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb23-13" data-line-number="13">        <span class="dt">panel.grid.major.y =</span> <span class="kw">element_blank</span>())</a></code></pre></div>
<p><img src="/class/11-class_files/figure-html/plot-bom-hapax-1.png" width="1152" /></p>
</figure>
<h4 id="verse-length">Verse length</h4>
<p>We can also make a fingerprint based on verse length. Here we use the Old and New Testaments, just for fun. Job, Psalms, and Proverbs all have really short verses, as do the first few chapters in 1 Chronicles. The verses in Revelation are longer, as are the verses in Hebrew and 2 Peter. The verse length in Luke and Acts appears to be roughly the same.</p>
<figure class="fullwidth">
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb24-1" data-line-number="1"><span class="co"># Count how many characters there are in each verse, then calculate the average</span></a>
<a class="sourceLine" id="cb24-2" data-line-number="2"><span class="co"># verse length per chapter</span></a>
<a class="sourceLine" id="cb24-3" data-line-number="3">bible_verse_length &lt;-<span class="st"> </span>bible <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb24-4" data-line-number="4"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">verse_length =</span> <span class="kw">nchar</span>(scripture_text)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb24-5" data-line-number="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">book_title =</span> <span class="kw">fct_inorder</span>(book_title)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb24-6" data-line-number="6"><span class="st">  </span><span class="kw">group_by</span>(volume_title, book_title, chapter_number) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb24-7" data-line-number="7"><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">avg_verse =</span> <span class="kw">mean</span>(verse_length))</a>
<a class="sourceLine" id="cb24-8" data-line-number="8"></a>
<a class="sourceLine" id="cb24-9" data-line-number="9"><span class="co"># Plot this</span></a>
<a class="sourceLine" id="cb24-10" data-line-number="10"><span class="kw">ggplot</span>(bible_verse_length, </a>
<a class="sourceLine" id="cb24-11" data-line-number="11">       <span class="kw">aes</span>(<span class="dt">x =</span> chapter_number, <span class="dt">y =</span> <span class="kw">fct_rev</span>(book_title), <span class="dt">fill =</span> avg_verse)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb24-12" data-line-number="12"><span class="st">  </span><span class="kw">geom_tile</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb24-13" data-line-number="13"><span class="st">  </span><span class="kw">scale_fill_viridis_c</span>(<span class="dt">direction =</span> <span class="dv">-1</span>, <span class="dt">option =</span> <span class="st">&quot;plasma&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb24-14" data-line-number="14"><span class="st">  </span><span class="kw">guides</span>(<span class="dt">fill =</span> <span class="kw">guide_colorbar</span>(<span class="dt">barwidth =</span> <span class="dv">20</span>, <span class="dt">barheight =</span> <span class="fl">0.5</span>, <span class="dt">title.position =</span> <span class="st">&quot;top&quot;</span>,</a>
<a class="sourceLine" id="cb24-15" data-line-number="15">                               <span class="dt">title =</span> <span class="st">&quot;Average number of characters in verse&quot;</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb24-16" data-line-number="16"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Chapter&quot;</span>, <span class="dt">y =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb24-17" data-line-number="17"><span class="st">  </span><span class="kw">theme_minimal</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb24-18" data-line-number="18"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;bottom&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb24-19" data-line-number="19"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span><span class="kw">fct_rev</span>(volume_title), <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>)</a></code></pre></div>
<p><img src="/class/11-class_files/figure-html/bible-verse-length-1.png" width="960" /></p>
</figure>
<h4 id="text-features">Text features</h4>
<p>Finally, we can use the big guns and get all sorts of interesting features for every verse, like the number of punctuation marks, capital letters, periods, etc. using the <code>textfeatures()</code> function:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb25-1" data-line-number="1"><span class="co"># For textfeatures() to work, the column with the text in it has to be named text</span></a>
<a class="sourceLine" id="cb25-2" data-line-number="2">bom_features &lt;-<span class="st"> </span>bom <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb25-3" data-line-number="3"><span class="st">  </span><span class="kw">rename</span>(<span class="dt">text =</span> scripture_text) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb25-4" data-line-number="4"><span class="st">  </span><span class="co"># Don&#39;t calculate sentiment because it takes a little longer. Also don&#39;t</span></a>
<a class="sourceLine" id="cb25-5" data-line-number="5"><span class="st">  </span><span class="co"># calculate word2vec dimensions, since these take longer to do and they&#39;re</span></a>
<a class="sourceLine" id="cb25-6" data-line-number="6"><span class="st">  </span><span class="co"># kinda weird and uninterpretable. Also don&#39;t normalize the final</span></a>
<a class="sourceLine" id="cb25-7" data-line-number="7"><span class="st">  </span><span class="co"># numbers---keep them as raw numbers</span></a>
<a class="sourceLine" id="cb25-8" data-line-number="8"><span class="st">  </span><span class="kw">textfeatures</span>(<span class="dt">sentiment =</span> <span class="ot">FALSE</span>, <span class="dt">word2vec_dims =</span> <span class="ot">FALSE</span>, <span class="dt">normalize =</span> <span class="ot">FALSE</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb25-9" data-line-number="9"><span class="st">  </span><span class="co"># Add the BoM text back to the data frame, since textfeatures wiped it out</span></a>
<a class="sourceLine" id="cb25-10" data-line-number="10"><span class="st">  </span><span class="kw">bind_cols</span>(bom)</a>
<a class="sourceLine" id="cb25-11" data-line-number="11"></a>
<a class="sourceLine" id="cb25-12" data-line-number="12"><span class="co"># Look at all these columns you can work with now!</span></a>
<a class="sourceLine" id="cb25-13" data-line-number="13"><span class="kw">glimpse</span>(bom_features)</a></code></pre></div>
<pre><code>## Observations: 6,604
## Variables: 31
## $ volume_title     &lt;chr&gt; &quot;Book of Mormon&quot;, &quot;Book of Mormon&quot;, &quot;Book of ...
## $ n_urls           &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...
## $ n_hashtags       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...
## $ n_mentions       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...
## $ n_chars          &lt;int&gt; 304, 104, 97, 251, 114, 178, 134, 213, 114, 9...
## $ n_commas         &lt;int&gt; 7, 2, 0, 6, 5, 1, 1, 4, 1, 1, 2, 1, 7, 7, 4, ...
## $ n_digits         &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...
## $ n_exclaims       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, ...
## $ n_extraspaces    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...
## $ n_lowers         &lt;int&gt; 288, 97, 89, 235, 105, 172, 128, 204, 109, 90...
## $ n_lowersp        &lt;dbl&gt; 0.9475410, 0.9333333, 0.9183673, 0.9365079, 0...
## $ n_periods        &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, ...
## $ n_words          &lt;int&gt; 68, 25, 27, 56, 28, 46, 33, 46, 30, 20, 35, 1...
## $ n_caps           &lt;int&gt; 6, 4, 5, 6, 3, 2, 3, 4, 2, 1, 1, 3, 7, 8, 3, ...
## $ n_nonasciis      &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...
## $ n_puncts         &lt;int&gt; 2, 0, 2, 3, 0, 2, 1, 0, 1, 0, 1, 0, 4, 3, 1, ...
## $ n_capsp          &lt;dbl&gt; 0.02295082, 0.04761905, 0.06122449, 0.0277777...
## $ n_charsperword   &lt;dbl&gt; 4.420290, 4.038462, 3.500000, 4.421053, 3.965...
## $ n_polite         &lt;dbl&gt; 0.0000000, 0.0000000, -0.2500000, 0.0000000, ...
## $ n_first_person   &lt;int&gt; 2, 2, 3, 1, 1, 0, 0, 0, 0, 0, 1, 0, 2, 1, 2, ...
## $ n_first_personp  &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...
## $ n_second_person  &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...
## $ n_second_personp &lt;int&gt; 0, 0, 1, 2, 3, 2, 3, 2, 3, 1, 1, 2, 2, 2, 2, ...
## $ n_third_person   &lt;int&gt; 0, 0, 1, 2, 1, 0, 1, 2, 1, 2, 2, 1, 1, 3, 0, ...
## $ n_tobe           &lt;int&gt; 2, 0, 1, 2, 0, 0, 1, 2, 1, 0, 0, 1, 2, 2, 1, ...
## $ n_prepositions   &lt;int&gt; 2, 2, 2, 5, 4, 4, 4, 4, 5, 2, 4, 3, 4, 4, 4, ...
## $ volume_title1    &lt;chr&gt; &quot;Book of Mormon&quot;, &quot;Book of Mormon&quot;, &quot;Book of ...
## $ book_title       &lt;fct&gt; 1 Nephi, 1 Nephi, 1 Nephi, 1 Nephi, 1 Nephi, ...
## $ chapter_number   &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
## $ verse_number     &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...
## $ scripture_text   &lt;chr&gt; &quot;I, Nephi, having been born of goodly parents...</code></pre>
<h2 id="clearest-and-muddiest-things">Clearest and muddiest things</h2>
<p>Go to <a href="https://goo.gl/forms/rSIbw1voOV2vWKMD2">this form</a> and answer these two questions:</p>
<ol style="list-style-type: decimal">
<li>What was the muddiest thing from class today? What are you still wondering about?</li>
<li>What was the clearest thing from class today? What was the most exciting thing you learned?</li>
</ol>
<p>I’ll compile the questions and send out answers after class.</p>
